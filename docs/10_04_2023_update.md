# Webcam Dataset - Updates

## Scraping - [`scraping`](https://github.com/thesstefan/vae_weather_translation/tree/main/teshub/scraping) module and the [`scraper_cli`](https://github.com/thesstefan/vae_weather_translation/blob/main/teshub/cli/scraper_cli.py) script

Webcam scraping part is now 100% done, no further changes needed here.
  - Streams are identified and frames are scraped asynchronously
  - Relevant metadata such as location and categories are also scraped
  - Everything is automatically persisted in CSV file (see section below)
  - Scraped around `5000 Streams ~ 250.000 Frames ~ 25GB`. Could easily download more if needed.

## CSV Persistence - [`dataset`](https://github.com/thesstefan/vae_weather_translation/tree/main/teshub/dataset) module
The dataset keeps track webcam metadata and status through CSV files. Every step that a webcam goes through while creating the dataset, from download 
to segmentation and validation is tracked through them. There are two kind of CSV files:

1. Webcam CSV that contains information about all streams. This is where general information about a webcam is stored:

| id         | status             | image_count | categories                  | city           | region | country     | continent | latitude  | longitude |
| ---------- | ------------------ | ----------- | --------------------------- | -------------- | ------ | ----------- | --------- | --------- | --------- |
| 1081757307 | PARTIAL_ANNOTATION | 53          | landscape, mountain         | Eriz           | Bern   | Switzerland | Europe    | 46.790783 | 7.743511  |
| 1010004899 | TASK_CREATED       | 53          | landscape, lake             | Beinwil am See | Aargau | Switzerland | Europe    | 47.269445 | 8.21125   |
| 1010220186 | DELETED            | 36          | landscape, mountain         | Fieschertal    | Valais | Switzerland | Europe    | 46.548472 | 7.988091  | 
| 1010222761 | DOWNLOADED         | 32          | landscape, mountain         | Grindelwald    | Bern   | Switzerland | Europe    | 46.611243 | 7.942085  |

2. Webcam Frame CSV that contains information about each frame in a stream. Each webcam directory contains one such CSV file. This is generally
used for annotation/validation purposes:

| file_name                   | status            | segmentation_path             | labels                                            |
| --------------------------- | ------------------| ----------------------------- | ------------------------------------------------- |
| 1081757307@1649070627.jpg   | DELETED           | NONE                          | NONE                                              |
| 1081757307@1649675196.jpg   | DOWNLOADED        | NONE                          | NONE                                              |
| 1081757307@1651486519.jpg   | MANUAL_ANNOTATION | 1081757307@1651486519_seg.png | snowy: 0.0, rainy: 0.0, foggy: 0.0, cloudy: 0.125 |
| 1081757307@1659352395.jpg   | MANUAL_ANNOTATION | 1081757307@1659352395_seg.png | snowy: 0.0, rainy: 0.0, foggy: 0.0, cloudy: 0.0   |

- CSV files are abstracted away through the [`WebcamDataset`](https://github.com/thesstefan/vae_weather_translation/blob/main/teshub/dataset/webcam_dataset.py) class
- Layers to easily convert to Python entities are provided
- Generally, the CSV files should *only* be modified through the provided scripts
- The main goal of the implementation is to avoid any kind of data corruption/loss

## Annotation & CVAT - [`annotation`](https://github.com/thesstefan/vae_weather_translation/tree/main/teshub/annotation) module the [`cvat_cli`](https://github.com/thesstefan/vae_weather_translation/blob/main/teshub/cli/cvat_cli.py) script
To annotate and validate webcams, [CVAT](https://www.cvat.ai/) is used. The `annotation` module provides utilities to easily integrate
the CVAT API with the webcam dataset. The user can add a webcam to annotation and sync task results locally (annotations, deleted frames, rejected webcams). 
This information is automatically persisted in the CSV files described above.

Below you can see how a good webcam stream generally looks:
  - No major defects
  - No big changes in scenery except weather (there are some images where a ladder appears, but they can be removed)
  - A varied scope of weather conditions (we can see snow, dark clouds, white clouds, clear and cloudy skies)

https://user-images.githubusercontent.com/16565342/230997199-3483b226-ab1e-4b39-9c45-0a00b0b06720.mov

For annotation, we use two type of items:
  - Segmentation masks: Bounding boxes/polygons around several weather-cues: white clouds, black clouds, shadows, snow, sun, blue sky, gray sky etc.
  - Weather "labels": We use 4 main categories (`snowy`, `rainy`, `foggy`, `cloudy`) that can be quantified with values between 0 and 1:
    - `cloudy=0` would mean clear sky, while `cloudy=1` would mean sky full of clouds. 
       Although pretty subjective, the goal would be to get a value for "How X it is?". Therefore, we annotate with this in mind and use intermediary values

Below you can see two pictures, showing how the segmentation process looks and what the end result that is added to the dataset looks like:

![image](https://user-images.githubusercontent.com/16565342/231001759-77657e3f-6e2e-4596-aa46-3866b19db4a4.png)
![1081757307@1659352395](https://user-images.githubusercontent.com/16565342/231001651-20a179a5-8f08-4c07-a251-911adce6c70d.png)

# Future

The next goal is to annotate some images as described and create a model that can automatically annotate the other images. A multi-task model similar to 
the one proposed [here](https://www.sciencedirect.com/science/article/abs/pii/S0031320319302481) could be used (if the datasets/models used here were available, 
we could have used these instead of doing thins from scratch :(). The paper datasets used 10k annotated images for training their model, so I expect the same 
in my case.

I think I have these options going forward:
  
1. Annotate 10k images manually on my own (I expect this to take around one week at 8 hours per day :()
2. Train a model and assume it's successful
3. Annotate the rest of the images (not sure how many are needed, but could do up to 250k)
4. Validate results
    1. Continue as planned, going forward with weather translation  
    2. Reduce scope, and instead try to use some different approaches to segmentation and finetune the model proposed in the paper. Could also make
  some interesting additions by using pseudo-regression+classification instead of the simple classification used in the paper.
  
The other option is reducing scope... and trying something else?
